‚û°Ô∏è Techniques for prompting

There are some basic techniques that we can use to prompt an LLM:

‚óΩZero-shot prompting
‚Ä¢This is the most basic form of prompting 
‚Ä¢It's a single prompt requesting a response from the LLM based solely on its training data.

‚óΩFew-shot prompting
‚Ä¢This type of prompting guides the LLM by providing 1 or more examples it can rely on to generate its response.

‚óΩChain-of-thought 
‚Ä¢This type of prompting tells the LLM how to break down a problem into steps.
‚Ä¢We guide AI model to take steps like first do A, then B, then C and so on to reach the solution 
‚Ä¢The model will mimic that and can take on more advance problems. 


‚óΩGenerated knowledge
‚Ä¢to improve the response of a prompt
‚Ä¢Can provide generated facts or knowledge additionally to your prompt.

‚óΩLeast to most (like chain-of-thought)
‚Ä¢This technique is about breaking down a problem into a series of steps and then ask these steps to be performed in order.

üî∂Below two for validating response : 

‚óΩSelf-refine, 
‚Ä¢This technique is about critiquing the LLM's output and then asking it to improve.
‚Ä¢We're asking that are you sure about these facts? 
‚Ä¢How about going for a another round!!

‚óΩMaieutic prompting
‚Ä¢What you want here is to ensure the LLM answer is correct and you ask it to explain various parts of the answer. This is a form of self-refine.