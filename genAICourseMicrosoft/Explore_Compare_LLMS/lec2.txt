➡️ Different types of models : 

◽For Audio and speech recognition: Whisper-type models
• It's trained on diverse audio and can perform multilingual speech recognition.  
• The Whisper model is a speech to text model from OpenAI
• transcribe or translate audio files
• The model is trained on a large dataset of English audio and text

◽For Image generation: DALL-E / Midjourney / Stable diffudion models 
Image dataset eg: LAION-5B
• Midjourney is known for its artistic flair and ability to create highly stylized, realistic images, particularly excelling in mood and creative visuals
•DALL-E, now powered by GPT-4o, is known for its accuracy in interpreting prompts and generating images that closely match the text description, making it ideal for quick, precise, and literal image creation.

◽Text generation
Dataset eg : BookCorpus
•GPT-3.5 to GPT-4
•Code generator model : CodeParrot

◽Multi-modality
•handle multiple types of data in input and output ; models like gpt-4 turbo with vision or gpt-4o will help



➡️Foundation Models versus LLMs : 

FM follows some criteria:
•They are trained using unsupervised learning or self-supervised learning (unlabeled multi-modal data)
•They are very large models(trained on billions of parameters)
•They are normally intended to serve as a ‘foundation’ for other models : It provides us a base and later we can fine tune it as well

◽ Inside FM comes LLM i.e vhatgpt , chinchilla , gpt-3 etc



➡️Open Source versus Proprietary Models:

•OSM are made available to the public and can be used by anyone. 
•Not for production use 
•allowed to be inspected, modified, and customized for the various use cases in LLMs
• < performance then PM
•Eg. Alpaca, Bloom and LLaMA.


•PM are owned by a company and are not made available to the public
•optimized for production use
•not allowed to be ............
•not free ; requires subscription/payment 
•users do not have control over the data that is used to train the model (dependent on owner for data privacy and responsible use of it)
•Eg: OpenAI models, Google Bard or Claude 2.


➡️Embedding v/s Image generation v/s Text and Code generation

◽Embeddings : convert text into a numerical form, called embedding, which is a numerical representation of the input text
◽make it easier for machines to understand the relationships between words or sentences
◽can be consumed as inputs by other models
◽Eg: OpenAI embeddings


➡️Encoder-Decoder versus Decoder-only

◽Decoder-only : They are very good at writing engaging and informative content, but they are not very good at understanding the topic and the learning objectives. (Only create)
•Eg: GPT family models, such as GPT-3. 

◽Encoder only model : notice relationships b/w content , understand context but not good at generating content (Only understands)
•Eg : BERT

◽Encoder-Decoder model : create and review both (Do both)
•Eg: BART and T5



➡️Service versus Model

◽A service is a product that is offered by a Cloud Service Provider, and is often a combination of models, data, and other components.
    •optimized for production use
    •easy to use via GUI
    •not free but are scalable
    •Eg : Azure OpenAI Service (Pay-per-use)


◽A model is the core component of a service, and is often a foundation model, such as an LLM.
    •just the Neural Network, with the parameters, weights, and others
    •need to buy equipment
    •build a structure to scale
    •buy a license or use an open-source model
    •Eg: LLaMA




➡️Improving LLM results
◽Prompt engineering with context : give enough context for better results
◽Retrieval Augmented Generation, RAG : Pre-trained data + data from other sources like database , internet , web endpoint or from anywhere else 
    •LLMs ➕ external knowledge base (in the form of chunks of documents) 
    •allowing them to access and incorporate up-to-date information before generating responses.
    •supported by Vector database tools (like Azure Vector Search)  
    •retrieve the useful chunks from varied pre-defined data sources and add them to the prompt Context.

    •used when company have less data but wishes to improve performance on a specific workload and reduce risks of fabrications

◽Fine-tuned model : you trained the model further on your own data
    •leverages transfer learning to ‘adapt’ the model
    •to solve a specific problem
    •new model is generated with updated weights and biases
    •use when you need less latency
    •use when uou need to stay up to date
    •use when you have time and resources and high quality data

◽Trained model
    •when business has a domain-specific use case
    •large amount of domain-centric data.



➡️Prompt Engineering with Context (most cost-effective approach to kick-off with)

◽“zero-shot” learning : short prompt, like a sentence to complete or a question
◽“one-shot” learning : prompt includes only one example
◽“few shot learning” : prompt includes multiple examples
